{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7616b07e-d8be-4bbc-a973-33082f6c7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def generate_cam(model, img_array, class_index, last_conv_layer_name):\n",
    "#     # Define a model that outputs the activations of the last conv layer and the output predictions\n",
    "#     last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "#     last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "#     # Get the gradients of the last conv layer with respect to the output\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         conv_outputs = last_conv_layer_model(img_array)\n",
    "#         tape.watch(conv_outputs)\n",
    "#         preds = model(img_array)\n",
    "#         loss = preds[:, class_index]\n",
    "\n",
    "#     # Calculate the gradients\n",
    "#     grads = tape.gradient(loss, conv_outputs)\n",
    "\n",
    "#     # Global average pooling\n",
    "#     pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "#     # Multiply each channel in the feature map array by \"how important this channel is\" with regard to the class\n",
    "#     heatmap = tf.reduce_mean(conv_outputs * pooled_grads[..., tf.newaxis], axis=-1)\n",
    "\n",
    "#     # Normalize the heatmap\n",
    "#     heatmap = np.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
    "\n",
    "#     return heatmap.numpy()\n",
    "\n",
    "# def overlay_cam(image_path, heatmap):\n",
    "#     # Load the original image\n",
    "#     img = cv2.imread(image_path)\n",
    "\n",
    "#     # Resize the heatmap to match the size of the original image\n",
    "#     heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "#     # Convert the heatmap to RGB\n",
    "#     heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "#     # Apply the heatmap to the original image\n",
    "#     heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "#     # Overlay the heatmap onto the original image\n",
    "#     overlayed_img = cv2.addWeighted(img, 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "#     return overlayed_img\n",
    "\n",
    "# # Example usage:\n",
    "# # Load your pre-trained model\n",
    "# from keras.models import load_model\n",
    "# # model = tf.keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "# model = load_model('C:\\\\Users\\\\Krishang Virmani\\\\Desktop\\\\Python CB\\\\ADNI\\\\CNN_model.h5')\n",
    "\n",
    "# # Load and preprocess the image\n",
    "# image_path = 'path/to/your/image.jpg'\n",
    "# img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "# img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "# img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
    "\n",
    "# # Generate CAM\n",
    "# class_index = np.argmax(model.predict(img_array))\n",
    "# heatmap = generate_cam(model, img_array, class_index, 'block5_conv3')\n",
    "\n",
    "# # Overlay CAM onto the original image\n",
    "# overlayed_img = overlay_cam(image_path, heatmap)\n",
    "\n",
    "# # Visualize the results\n",
    "# plt.imshow(overlayed_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbde5a1f-a052-49c3-9122-5648ba0c2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras \n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 # VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19 # VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 # ResNet50\n",
    "from tensorflow.keras.applications import ResNet101 # ResNet 101\n",
    "from tensorflow.keras.applications.xception import Xception # Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet # MobileNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\n",
    "from tensorflow.keras.applications.densenet import DenseNet121 # DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 # MobileNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441e700a-ab3d-4909-8432-6a8caad6d226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d042997-6eb6-4ad0-865b-54e9b2d99dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'C:\\\\Users\\\\Krishang Virmani\\\\Desktop\\\\Python CB\\\\ADNI\\\\Alzheimer_s Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7cda51-53a7-4260-87ba-12c5cc40f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for subfolder in os.listdir(dataset_path):\n",
    "    subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "    \n",
    "    \n",
    "    if os.path.isdir(subfolder_path):\n",
    "        \n",
    "        for folder in os.listdir(subfolder_path):\n",
    "            folder_path = os.path.join(subfolder_path, folder)\n",
    "            \n",
    "            \n",
    "            if os.path.isdir(folder_path):\n",
    "                \n",
    "                for image_filename in os.listdir(folder_path):\n",
    "                   \n",
    "                    if image_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                        image_path = os.path.join(folder_path, image_filename)\n",
    "                        images.append(image_path)\n",
    "                        labels.append(folder)\n",
    "                            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d03c7973-2d06-40b5-b013-f3b351a00dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"image\":images,\"labels\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48369bd5-34b9-486c-b2c8-e7a7838ed606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>MildDemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>MildDemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>MildDemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>MildDemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>MildDemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>VeryMildDemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>VeryMildDemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>VeryMildDemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>VeryMildDemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...</td>\n",
       "      <td>VeryMildDemented</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image            labels\n",
       "0     C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...      MildDemented\n",
       "1     C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...      MildDemented\n",
       "2     C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...      MildDemented\n",
       "3     C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...      MildDemented\n",
       "4     C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...      MildDemented\n",
       "...                                                 ...               ...\n",
       "6395  C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...  VeryMildDemented\n",
       "6396  C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...  VeryMildDemented\n",
       "6397  C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...  VeryMildDemented\n",
       "6398  C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...  VeryMildDemented\n",
       "6399  C:\\Users\\Krishang Virmani\\Desktop\\Python CB\\AD...  VeryMildDemented\n",
       "\n",
       "[6400 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b920344-95f1-49b8-b2e9-9f1db905793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79f9e917-c43c-4d36-afb0-bea8f6dfc58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mtrain_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mx_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mweight_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rgb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msave_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalidate_filenames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Takes the dataframe and the path to a directory + generates batches.\n",
       "\n",
       " The generated batches contain augmented/normalized data.\n",
       "\n",
       "**A simple tutorial can be found **[here](\n",
       "                            http://bit.ly/keras_flow_from_dataframe).\n",
       "\n",
       "Args:\n",
       "    dataframe: Pandas dataframe containing the filepaths relative to\n",
       "        `directory` (or absolute paths if `directory` is None) of the\n",
       "        images in a string column. It should include other column/s\n",
       "        depending on the `class_mode`:\n",
       "        - if `class_mode` is `\"categorical\"` (default value) it must\n",
       "            include the `y_col` column with the class/es of each image.\n",
       "            Values in column can be string/list/tuple if a single class\n",
       "            or list/tuple if multiple classes.\n",
       "        - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include\n",
       "            the given `y_col` column with class values as strings.\n",
       "        - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should\n",
       "            contain the columns specified in `y_col`.\n",
       "        - if `class_mode` is `\"input\"` or `None` no extra column is\n",
       "            needed.\n",
       "    directory: string, path to the directory to read images from. If\n",
       "      `None`, data in `x_col` column should be absolute paths.\n",
       "    x_col: string, column in `dataframe` that contains the filenames (or\n",
       "      absolute paths if `directory` is `None`).\n",
       "    y_col: string or list, column/s in `dataframe` that has the target\n",
       "      data.\n",
       "    weight_col: string, column in `dataframe` that contains the sample\n",
       "        weights. Default: `None`.\n",
       "    target_size: tuple of integers `(height, width)`, default: `(256,\n",
       "      256)`. The dimensions to which all images found will be resized.\n",
       "    color_mode: one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
       "      Whether the images will be converted to have 1 or 3 color\n",
       "      channels.\n",
       "    classes: optional list of classes (e.g. `['dogs', 'cats']`). Default\n",
       "      is None. If not provided, the list of classes will be\n",
       "      automatically inferred from the `y_col`, which will map to the\n",
       "      label indices, will be alphanumeric). The dictionary containing\n",
       "      the mapping from class names to class indices can be obtained via\n",
       "      the attribute `class_indices`.\n",
       "    class_mode: one of \"binary\", \"categorical\", \"input\", \"multi_output\",\n",
       "        \"raw\", sparse\" or None. Default: \"categorical\".\n",
       "        Mode for yielding the targets:\n",
       "        - `\"binary\"`: 1D numpy array of binary labels,\n",
       "        - `\"categorical\"`: 2D numpy array of one-hot encoded labels.\n",
       "          Supports multi-label output.\n",
       "        - `\"input\"`: images identical to input images (mainly used to\n",
       "          work with autoencoders),\n",
       "        - `\"multi_output\"`: list with the values of the different\n",
       "          columns,\n",
       "        - `\"raw\"`: numpy array of values in `y_col` column(s),\n",
       "        - `\"sparse\"`: 1D numpy array of integer labels,\n",
       "        - `None`, no targets are returned (the generator will only yield\n",
       "          batches of image data, which is useful to use in\n",
       "          `model.predict()`).\n",
       "    batch_size: size of the batches of data (default: 32).\n",
       "    shuffle: whether to shuffle the data (default: True)\n",
       "    seed: optional random seed for shuffling and transformations.\n",
       "    save_to_dir: None or str (default: None). This allows you to\n",
       "      optionally specify a directory to which to save the augmented\n",
       "      pictures being generated (useful for visualizing what you are\n",
       "      doing).\n",
       "    save_prefix: str. Prefix to use for filenames of saved pictures\n",
       "      (only relevant if `save_to_dir` is set).\n",
       "    save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n",
       "      \"tif\", \"jpg\" (only relevant if `save_to_dir` is set). Default:\n",
       "      \"png\".\n",
       "    subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
       "      `validation_split` is set in `ImageDataGenerator`.\n",
       "    interpolation: Interpolation method used to resample the image if\n",
       "      the target size is different from that of the loaded image.\n",
       "      Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n",
       "      If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n",
       "      supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n",
       "      `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n",
       "    validate_filenames: Boolean, whether to validate image filenames in\n",
       "      `x_col`. If `True`, invalid images will be ignored. Disabling this\n",
       "      option can lead to speed-up in the execution of this function.\n",
       "      Defaults to `True`.\n",
       "    **kwargs: legacy arguments for raising deprecation warnings.\n",
       "\n",
       "Returns:\n",
       "    A `DataFrameIterator` yielding tuples of `(x, y)`\n",
       "    where `x` is a numpy array containing a batch\n",
       "    of images with shape `(batch_size, *target_size, channels)`\n",
       "    and `y` is a numpy array of corresponding labels.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\krishang virmani\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\keras\\src\\preprocessing\\image.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_datagen.flow_from_dataframe?\n",
    "# (\n",
    "#     df,\n",
    "#     target_size=(224, 224),\n",
    "#     batch_size=16,\n",
    "#     class_mode='categorical',\n",
    "#     subset='training'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d893c43-fa00-47c4-8a57-78d3ad7feb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
